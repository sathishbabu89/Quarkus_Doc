def generate_savings_recommendations(financial_data):
    """Generate personalized and stylish savings recommendations using HuggingFace LLM"""
    client = InferenceClient(token=HUGGINGFACE_API_TOKEN)
    
    prompt = f"""
    [INST] As a financial advisor, analyze this financial data and provide personalized savings recommendations:
    
    - Monthly Income: €{financial_data.get('totalIncome', 0):,.2f}
    - Monthly Expenses: €{financial_data.get('totalExpenses', 0):,.2f}
    - Current Savings: €{financial_data.get('savings', 0):,.2f}
    - Spending by Category: {financial_data.get('spending_by_category', {})}
    
    Provide:
    1. Three specific savings opportunities based on spending patterns, with each opportunity highlighted with a meaningful emoji
    2. Recommended savings goals based on income level, presented with percentage targets
    3. Actionable steps to achieve these goals, presented as a mini-roadmap
    4. Potential long-term benefits of these savings, emphasized with compelling statistics or projections
    
    Format your response with clear headers, bullet points, and emphasize key numbers. Use professional but friendly language with occasional motivational phrases. [/INST]
    """
    
    response = client.text_generation(
        prompt,
        model="mistralai/Mistral-7B-Instruct-v0.3",
        max_new_tokens=512,
        temperature=0.7
    )
    
    # Format the response with markdown styling
    formatted_response = format_recommendations(response)
    
    return formatted_response

def format_recommendations(raw_response):
    """Add styling and formatting to the raw LLM response"""
    # This function could add markdown headers, bold important numbers,
    # ensure consistent spacing, add dividers between sections, etc.
    
    # Example implementation
    styled_response = raw_response
    
    # You could add more formatting logic here
    # For example: styling headers, adding emoji, formatting currency values
    
    return styled_response
